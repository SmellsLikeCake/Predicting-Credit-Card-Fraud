{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ccf = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccf.Class.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17275038271934384"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "492/284804*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial summary of data\n",
    "\n",
    "- There are 284,807 observations and 31 variables.\n",
    "- V1 to V28 are the components from PCA.\n",
    "- Time represents the seconds elapsed between each transaction and the first transaction in the dataset. Unlikely to be much use except perhaps for some form of seasonality?\n",
    "- Amount is the transaction amount.\n",
    "- Class is the response variable. Only 0.17% of the transactions are fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccf.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove time as seem arbitrary\n",
    "\n",
    "ccf = ccf.drop(['Time'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284807.000000\n",
       "mean         88.349619\n",
       "std         250.120109\n",
       "min           0.000000\n",
       "25%           5.600000\n",
       "50%          22.000000\n",
       "75%          77.165000\n",
       "max       25691.160000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccf['Amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1825"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccf.loc[ccf['Amount'] == 0, 'Amount'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1798\n",
       "1      27\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccf.loc[ccf['Amount'] == 0, 'Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5016685205784204"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27/1798*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccf_zero = ccf.loc[ccf['Amount'] == 0, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>-0.356466</td>\n",
       "      <td>0.725418</td>\n",
       "      <td>1.971749</td>\n",
       "      <td>0.831343</td>\n",
       "      <td>0.369681</td>\n",
       "      <td>-0.107776</td>\n",
       "      <td>0.751610</td>\n",
       "      <td>-0.120166</td>\n",
       "      <td>-0.420675</td>\n",
       "      <td>-0.059943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.424312</td>\n",
       "      <td>-0.015989</td>\n",
       "      <td>0.466754</td>\n",
       "      <td>-0.809962</td>\n",
       "      <td>0.657334</td>\n",
       "      <td>-0.043150</td>\n",
       "      <td>-0.046401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>-1.299837</td>\n",
       "      <td>0.881817</td>\n",
       "      <td>1.452842</td>\n",
       "      <td>-1.293698</td>\n",
       "      <td>-0.025105</td>\n",
       "      <td>-1.170103</td>\n",
       "      <td>0.861610</td>\n",
       "      <td>-0.193934</td>\n",
       "      <td>0.592001</td>\n",
       "      <td>0.241979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272563</td>\n",
       "      <td>-0.360853</td>\n",
       "      <td>0.223911</td>\n",
       "      <td>0.598930</td>\n",
       "      <td>-0.397705</td>\n",
       "      <td>0.637141</td>\n",
       "      <td>0.234872</td>\n",
       "      <td>0.021379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>1.237413</td>\n",
       "      <td>0.512365</td>\n",
       "      <td>0.687746</td>\n",
       "      <td>1.693872</td>\n",
       "      <td>-0.236323</td>\n",
       "      <td>-0.650232</td>\n",
       "      <td>0.118066</td>\n",
       "      <td>-0.230545</td>\n",
       "      <td>-0.808523</td>\n",
       "      <td>0.511284</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077543</td>\n",
       "      <td>-0.178220</td>\n",
       "      <td>0.038722</td>\n",
       "      <td>0.471218</td>\n",
       "      <td>0.289249</td>\n",
       "      <td>0.871803</td>\n",
       "      <td>-0.066884</td>\n",
       "      <td>0.012986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>-1.860258</td>\n",
       "      <td>-0.629859</td>\n",
       "      <td>0.966570</td>\n",
       "      <td>0.844632</td>\n",
       "      <td>0.759983</td>\n",
       "      <td>-1.481173</td>\n",
       "      <td>-0.509681</td>\n",
       "      <td>0.540722</td>\n",
       "      <td>-0.733623</td>\n",
       "      <td>-0.371622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268028</td>\n",
       "      <td>0.125515</td>\n",
       "      <td>-0.225029</td>\n",
       "      <td>0.586664</td>\n",
       "      <td>-0.031598</td>\n",
       "      <td>0.570168</td>\n",
       "      <td>-0.043007</td>\n",
       "      <td>-0.223739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V1        V2        V3        V4        V5        V6        V7  \\\n",
       "383 -0.356466  0.725418  1.971749  0.831343  0.369681 -0.107776  0.751610   \n",
       "514 -1.299837  0.881817  1.452842 -1.293698 -0.025105 -1.170103  0.861610   \n",
       "534  1.237413  0.512365  0.687746  1.693872 -0.236323 -0.650232  0.118066   \n",
       "541 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "575 -1.860258 -0.629859  0.966570  0.844632  0.759983 -1.481173 -0.509681   \n",
       "\n",
       "           V8        V9       V10  ...       V21       V22       V23  \\\n",
       "383 -0.120166 -0.420675 -0.059943  ...  0.020804  0.424312 -0.015989   \n",
       "514 -0.193934  0.592001  0.241979  ... -0.272563 -0.360853  0.223911   \n",
       "534 -0.230545 -0.808523  0.511284  ... -0.077543 -0.178220  0.038722   \n",
       "541  1.391657 -2.770089 -2.772272  ...  0.517232 -0.035049 -0.465211   \n",
       "575  0.540722 -0.733623 -0.371622  ...  0.268028  0.125515 -0.225029   \n",
       "\n",
       "          V24       V25       V26       V27       V28  Amount  Class  \n",
       "383  0.466754 -0.809962  0.657334 -0.043150 -0.046401     0.0      0  \n",
       "514  0.598930 -0.397705  0.637141  0.234872  0.021379     0.0      0  \n",
       "534  0.471218  0.289249  0.871803 -0.066884  0.012986     0.0      0  \n",
       "541  0.320198  0.044519  0.177840  0.261145 -0.143276     0.0      1  \n",
       "575  0.586664 -0.031598  0.570168 -0.043007 -0.223739     0.0      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccf_zero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccf_no_zero = ccf.loc[~ccf.index.isin(ccf_zero.index), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282982, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccf_no_zero.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning comments\n",
    "\n",
    "- Data contains no missing values.\n",
    "- Data contains 1,825 transactions of amount 0.\n",
    "- 1.5% of the 0 transactions are fraudulent - a much higher percentage.\n",
    "- Try modeling but including and excluding these transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(ccf.drop(['Class'], 1), \n",
    "                                                    ccf['Class'], \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=392,\n",
    "                                                    stratify = ccf['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199364, 29)\n",
      "(85443, 29)\n",
      "(199364,)\n",
      "(85443,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "print(y_train.sum())\n",
    "print(y_test.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_no0, x_test_no0, y_train_no0, y_test_no0 = train_test_split(ccf_no_zero.drop(['Class'], 1),\n",
    "                                                                    ccf_no_zero['Class'],\n",
    "                                                                    test_size=0.3,\n",
    "                                                                    random_state=392,\n",
    "                                                                    stratify=ccf_no_zero['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "print(y_train_no0.sum())\n",
    "print(y_test_no0.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "Assume all observations are classified as not fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives = 0\n",
      "True negatives = 199020\n",
      "False positives = 0\n",
      "False negatives = 344\n",
      "Sensitivity = 0.0\n",
      "Specificity = 1.0\n"
     ]
    }
   ],
   "source": [
    "print('True positives =', 0)\n",
    "print('True negatives =', (y_train == 0).sum())\n",
    "print('False positives =', 0)\n",
    "print('False negatives =', (y_train == 1).sum())\n",
    "\n",
    "print('Sensitivity =', 0 / (0 + (y_train == 1).sum()))\n",
    "print('Specificity =', (y_train == 0).sum() / ((y_train == 0).sum() + 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is prioritize finding fraud so the sensitivity needs to be as high as possible. Okay to have some false positives if minimize false negatives, though clearly unfeasible to assume all fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions\n",
    "#### Results function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(table):\n",
    "    print(table)\n",
    "    print('True positives =', table.iloc[1, 1])\n",
    "    print('True negatives =', table.iloc[0, 0])\n",
    "    print('False positives =', table.iloc[0, 1])\n",
    "    print('False negatives =', table.iloc[1, 0])\n",
    "    print('Sensitivity =', table.iloc[1, 1] / (table.iloc[1, 1] + table.iloc[1, 0]))\n",
    "    print('Specificity =', table.iloc[0,0] / (table.iloc[0, 0] + table.iloc[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_results(dict_of_models):\n",
    "    results = pd.DataFrame()\n",
    "    models = []\n",
    "    true_pos = []\n",
    "    true_neg = []\n",
    "    false_pos = []\n",
    "    false_neg = []\n",
    "    sens = []\n",
    "    specs = []\n",
    "    for model in dict_of_models:\n",
    "        models.append(model)\n",
    "        model_table = dict_of_models[model]\n",
    "        true_pos.append(model_table.iloc[1, 1])\n",
    "        true_neg.append(model_table.iloc[0, 0])\n",
    "        false_pos.append(model_table.iloc[0, 1])\n",
    "        false_neg.append(model_table.iloc[1, 0])\n",
    "        sens.append(model_table.iloc[1, 1] / (model_table.iloc[1, 1] + model_table.iloc[1, 0]))\n",
    "        specs.append(model_table.iloc[0, 0] / (model_table.iloc[0, 0] + model_table.iloc[0, 1]))\n",
    "    results['models'] = models\n",
    "    results['true_positives'] = true_pos\n",
    "    results['true_negatives'] = true_neg\n",
    "    results['false_positives'] = false_pos\n",
    "    results['false_negatives'] = false_neg\n",
    "    results['sensitivity'] = sens\n",
    "    results['specificity'] = specs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "### No regularization - 0.5 cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.004101\n",
      "         Iterations 13\n",
      "col_0       0    1\n",
      "Class             \n",
      "0      198987   33\n",
      "1         137  207\n",
      "True positives = 207\n",
      "True negatives = 198987\n",
      "False positives = 33\n",
      "False negatives = 137\n",
      "Sensitivity = 0.6017441860465116\n",
      "Specificity = 0.9998341875188423\n"
     ]
    }
   ],
   "source": [
    "## Add intercept column\n",
    "x_train_int = x_train\n",
    "x_train_int['intercept'] = 1\n",
    "\n",
    "## Fit model\n",
    "logit = sm.Logit(y_train, x_train_int)\n",
    "logit_result = logit.fit()\n",
    "\n",
    "## Check accuracy on training set\n",
    "pred_logit_train = logit_result.predict(x_train_int)\n",
    "pred_y_logit_train = np.where(pred_logit_train < .5, 0, 1)\n",
    "\n",
    "logit_table = pd.crosstab(y_train, pred_y_logit_train)\n",
    "\n",
    "print_results(logit_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=0.709 auc=0.754 ap=0.754\n"
     ]
    }
   ],
   "source": [
    "precision_logit, recall_logit, thresholds_logit = precision_recall_curve(y_train, pred_logit_train)\n",
    "f1_logit = f1_score(y_train, pred_y_logit_train)\n",
    "auc_logit = auc(recall_logit, precision_logit)\n",
    "ap_logit = average_precision_score(y_train, pred_logit_train)\n",
    "print('f1=%.3f auc=%.3f ap=%.3f'% (f1_logit, auc_logit, ap_logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No regularization - 0.0017 cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.004101\n",
      "         Iterations 13\n",
      "col_0       0     1\n",
      "Class              \n",
      "0      190047  8973\n",
      "1          33   311\n",
      "True positives = 311\n",
      "True negatives = 190047\n",
      "False positives = 8973\n",
      "False negatives = 33\n",
      "Sensitivity = 0.9040697674418605\n",
      "Specificity = 0.9549140789870365\n"
     ]
    }
   ],
   "source": [
    "## Redo but with cutoff equal to proportion of positive class\n",
    "\n",
    "## Fit model\n",
    "logit_2 = sm.Logit(y_train, x_train_int)\n",
    "logit_2_result = logit_2.fit()\n",
    "\n",
    "## Check accuracy on training set\n",
    "pred_logit_2_train = logit_2_result.predict(x_train_int)\n",
    "pred_y_logit_2_train = np.where(pred_logit_2_train < .0017, 0, 1)\n",
    "\n",
    "logit_2_table = pd.crosstab(y_train, pred_y_logit_2_train)\n",
    "\n",
    "print_results(logit_2_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=0.065 auc=0.754 ap=0.754\n"
     ]
    }
   ],
   "source": [
    "## Check accuracy using Area Under Precision Recall Curve (AUPRC)\n",
    "\n",
    "## Precision = true positives / (true positives + false positives)\n",
    "## Recall = true positives / (true positives + false negatives)\n",
    "\n",
    "precision_logit_2, recall_logit_2, thresholds_logit_2 = precision_recall_curve(y_train, pred_logit_2_train)\n",
    "f1_logit_2 = f1_score(y_train, pred_y_logit_2_train)\n",
    "auc_logit_2 = auc(recall_logit_2, precision_logit_2)\n",
    "ap_logit_2 = average_precision_score(y_train, pred_logit_2_train)\n",
    "print('f1=%.3f auc=%.3f ap=%.3f'% (f1_logit_2, auc_logit_2, ap_logit_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0, 1], [0.0017, 0.0017], linestyle='--')\n",
    "plt.plot(recall_logit_2, precision_logit_2, marker='.')\n",
    "plt.xlabel('Sensitivity (positives found)')\n",
    "plt.ylabel('Precision (avoiding false positives)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try searching for better cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_logit_threshold(model, x, y, start, end, step):\n",
    "    thresholds = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "    for threshold in np.arange(start, end + step, step):\n",
    "        pred_y_probs = model.predict(x)\n",
    "        pred_y_outcome = np.where(pred_y_probs < threshold, 0, 1)\n",
    "        table = pd.crosstab(y, pred_y_outcome)\n",
    "        thresholds.append(threshold)\n",
    "        sensitivities.append(table.iloc[1, 1] / (table.iloc[1, 1] + table.iloc[1, 0]))\n",
    "        specificities.append(table.iloc[0, 0] / (table.iloc[0, 0] + table.iloc[0, 1]))\n",
    "        results_df = pd.DataFrame({'threshold': thresholds,\n",
    "        'sensitivity': sensitivities,\n",
    "        'specificity': specificities})\n",
    "        results_df['sum'] = results_df['sensitivity'] + results_df['specificity']\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.774374</td>\n",
       "      <td>1.739491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.904115</td>\n",
       "      <td>1.834348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.904070</td>\n",
       "      <td>0.946066</td>\n",
       "      <td>1.850135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.892442</td>\n",
       "      <td>0.964727</td>\n",
       "      <td>1.857169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.889535</td>\n",
       "      <td>0.974776</td>\n",
       "      <td>1.864311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.886628</td>\n",
       "      <td>0.980922</td>\n",
       "      <td>1.867549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.877907</td>\n",
       "      <td>0.985182</td>\n",
       "      <td>1.863089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.988247</td>\n",
       "      <td>1.863247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.869186</td>\n",
       "      <td>0.990308</td>\n",
       "      <td>1.859494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.869186</td>\n",
       "      <td>0.991604</td>\n",
       "      <td>1.860790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.863372</td>\n",
       "      <td>0.992775</td>\n",
       "      <td>1.856147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.863372</td>\n",
       "      <td>0.993589</td>\n",
       "      <td>1.856961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.854651</td>\n",
       "      <td>0.994317</td>\n",
       "      <td>1.848968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.854651</td>\n",
       "      <td>0.994784</td>\n",
       "      <td>1.849436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.854651</td>\n",
       "      <td>0.995413</td>\n",
       "      <td>1.850064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.854651</td>\n",
       "      <td>0.995915</td>\n",
       "      <td>1.850566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.854651</td>\n",
       "      <td>0.996402</td>\n",
       "      <td>1.851054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.851744</td>\n",
       "      <td>0.996809</td>\n",
       "      <td>1.848554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  sensitivity  specificity       sum\n",
       "0      0.0005     0.965116     0.774374  1.739491\n",
       "1      0.0010     0.930233     0.904115  1.834348\n",
       "2      0.0015     0.904070     0.946066  1.850135\n",
       "3      0.0020     0.892442     0.964727  1.857169\n",
       "4      0.0025     0.889535     0.974776  1.864311\n",
       "5      0.0030     0.886628     0.980922  1.867549\n",
       "6      0.0035     0.877907     0.985182  1.863089\n",
       "7      0.0040     0.875000     0.988247  1.863247\n",
       "8      0.0045     0.869186     0.990308  1.859494\n",
       "9      0.0050     0.869186     0.991604  1.860790\n",
       "10     0.0055     0.863372     0.992775  1.856147\n",
       "11     0.0060     0.863372     0.993589  1.856961\n",
       "12     0.0065     0.854651     0.994317  1.848968\n",
       "13     0.0070     0.854651     0.994784  1.849436\n",
       "14     0.0075     0.854651     0.995413  1.850064\n",
       "15     0.0080     0.854651     0.995915  1.850566\n",
       "16     0.0085     0.854651     0.996402  1.851054\n",
       "17     0.0090     0.851744     0.996809  1.848554"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logit_threshold(logit_2_result, x_train_int, y_train, 0.0005, 0.009, 0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sensitivity is highest at the lowest threshold, but the specificity is very poor at this level. The best of both occurs at around 0.003."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      0     1\n",
      "Class             \n",
      "0      83695  1600\n",
      "1         12   136\n",
      "True positives = 136\n",
      "True negatives = 83695\n",
      "False positives = 1600\n",
      "False negatives = 12\n",
      "Sensitivity = 0.918918918918919\n",
      "Specificity = 0.9812415733630342\n"
     ]
    }
   ],
   "source": [
    "## Test final model on test set\n",
    "\n",
    "pred_logit_3_test = logit_2_result.predict(x_test_int)\n",
    "pred_y_logit_3_test = np.where(pred_logit_3_test <.003, 0, 1)\n",
    "\n",
    "table_logit_3_test = pd.crosstab(y_test, pred_y_logit_3_test)\n",
    "\n",
    "print_results(table_logit_3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models = dict()\n",
    "final_models['logit_3'] = table_logit_3_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression - L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0       0    1\n",
      "Class             \n",
      "0      198987   33\n",
      "1         137  207\n",
      "True positives = 207\n",
      "True negatives = 198987\n",
      "False positives = 33\n",
      "False negatives = 137\n",
      "Sensitivity = 0.6017441860465116\n",
      "Specificity = 0.9998341875188423\n"
     ]
    }
   ],
   "source": [
    "## Try ridge with default values first to get a sense\n",
    "\n",
    "ridge = LogisticRegression(solver='liblinear', \n",
    "                           penalty='l2', \n",
    "                           random_state=392)\n",
    "ridge.fit(x_train, y_train)\n",
    "pred_y_ridge_train = ridge.predict(x_train)\n",
    "table_ridge_train = pd.crosstab(y_train, pred_y_ridge_train)\n",
    "print_results(table_ridge_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid search the C parameter\n",
    "\n",
    "c_grid = {'C': np.arange(0.1, 2.1, 0.1)}\n",
    "ridge_grid = GridSearchCV(estimator=ridge, \n",
    "                          param_grid = c_grid,\n",
    "                          cv=5,\n",
    "                          verbose=0,\n",
    "                          scoring='average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=392, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
       "       1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='average_precision', verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=392, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([3.37767901, 3.04820542, 3.9584516 , 3.41093292, 3.35441251,\n",
       "        3.34827151, 3.58330688, 3.69988499, 3.66092958, 3.38117099,\n",
       "        3.08976641, 3.55422173, 3.37885184, 3.41039314, 3.67966099,\n",
       "        3.30953655, 3.67649341, 3.56263804, 3.34189973, 3.39653234]),\n",
       " 'std_fit_time': array([0.23008236, 0.42226773, 0.91163141, 0.58241529, 0.29140754,\n",
       "        0.35839435, 0.6222657 , 0.67381371, 0.63041807, 0.32835914,\n",
       "        0.2527063 , 0.51900235, 0.42342044, 0.20127462, 0.31606241,\n",
       "        0.43570985, 0.47426379, 0.45851529, 0.49993829, 0.45042755]),\n",
       " 'mean_score_time': array([0.02546983, 0.02301073, 0.03009796, 0.02208962, 0.02282109,\n",
       "        0.0229702 , 0.02251859, 0.02365341, 0.02705216, 0.02415853,\n",
       "        0.02117243, 0.02352371, 0.02255559, 0.02207365, 0.02355981,\n",
       "        0.02334318, 0.02305923, 0.02184749, 0.02191658, 0.02186937]),\n",
       " 'std_score_time': array([0.00311927, 0.00182406, 0.00888095, 0.00229575, 0.00171335,\n",
       "        0.00196044, 0.00169997, 0.00164969, 0.00720337, 0.00250932,\n",
       "        0.00068717, 0.00211558, 0.00148964, 0.00164537, 0.00182639,\n",
       "        0.00432913, 0.00377971, 0.00172968, 0.0015412 , 0.00124282]),\n",
       " 'param_C': masked_array(data=[0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6,\n",
       "                    0.7000000000000001, 0.8, 0.9, 1.0, 1.1,\n",
       "                    1.2000000000000002, 1.3000000000000003,\n",
       "                    1.4000000000000001, 1.5000000000000002, 1.6,\n",
       "                    1.7000000000000002, 1.8000000000000003,\n",
       "                    1.9000000000000001, 2.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1},\n",
       "  {'C': 0.2},\n",
       "  {'C': 0.30000000000000004},\n",
       "  {'C': 0.4},\n",
       "  {'C': 0.5},\n",
       "  {'C': 0.6},\n",
       "  {'C': 0.7000000000000001},\n",
       "  {'C': 0.8},\n",
       "  {'C': 0.9},\n",
       "  {'C': 1.0},\n",
       "  {'C': 1.1},\n",
       "  {'C': 1.2000000000000002},\n",
       "  {'C': 1.3000000000000003},\n",
       "  {'C': 1.4000000000000001},\n",
       "  {'C': 1.5000000000000002},\n",
       "  {'C': 1.6},\n",
       "  {'C': 1.7000000000000002},\n",
       "  {'C': 1.8000000000000003},\n",
       "  {'C': 1.9000000000000001},\n",
       "  {'C': 2.0}],\n",
       " 'split0_test_score': array([0.71872107, 0.71628813, 0.71396523, 0.71172634, 0.71189061,\n",
       "        0.71137079, 0.71120601, 0.71071083, 0.71040618, 0.71009334,\n",
       "        0.70982047, 0.70932423, 0.70906403, 0.70899535, 0.70890204,\n",
       "        0.70849574, 0.70849324, 0.7082873 , 0.70836162, 0.70814467]),\n",
       " 'split1_test_score': array([0.75782197, 0.75612444, 0.75354444, 0.75255366, 0.75195083,\n",
       "        0.75065223, 0.75218965, 0.75148271, 0.75087036, 0.75063624,\n",
       "        0.74988986, 0.74938901, 0.74918516, 0.74913128, 0.74967473,\n",
       "        0.7488452 , 0.74852701, 0.74842047, 0.74826389, 0.74814554]),\n",
       " 'split2_test_score': array([0.75803296, 0.76163635, 0.76158753, 0.76004758, 0.75953412,\n",
       "        0.759206  , 0.75999765, 0.75955769, 0.75950954, 0.75903935,\n",
       "        0.75901959, 0.7587689 , 0.75875852, 0.75875475, 0.75874991,\n",
       "        0.75874061, 0.75876108, 0.75862194, 0.7586128 , 0.75861281]),\n",
       " 'split3_test_score': array([0.8123344 , 0.81074831, 0.81140471, 0.81167599, 0.81355846,\n",
       "        0.8131547 , 0.81317852, 0.81361639, 0.81384357, 0.81381937,\n",
       "        0.81335598, 0.81331929, 0.81335663, 0.81319987, 0.81321438,\n",
       "        0.81321601, 0.81322127, 0.81308378, 0.81312008, 0.81309736]),\n",
       " 'split4_test_score': array([0.68835757, 0.68888221, 0.68925813, 0.68876866, 0.68853378,\n",
       "        0.68844886, 0.68850328, 0.68841224, 0.68821049, 0.68785703,\n",
       "        0.68802188, 0.68738989, 0.6875685 , 0.68781432, 0.68779332,\n",
       "        0.68757265, 0.68777619, 0.68755934, 0.68765201, 0.68777046]),\n",
       " 'mean_test_score': array([0.74705389, 0.74673618, 0.74595229, 0.74495473, 0.74509385,\n",
       "        0.7445668 , 0.74501531, 0.74475625, 0.74456831, 0.74428935,\n",
       "        0.74402184, 0.74363855, 0.74358685, 0.74357939, 0.74366716,\n",
       "        0.74337432, 0.74335604, 0.74319485, 0.74320236, 0.74315445]),\n",
       " 'std_test_score': array([0.04182344, 0.04166973, 0.04200829, 0.04242224, 0.04299862,\n",
       "        0.04291108, 0.0430321 , 0.04321979, 0.04337105, 0.04346541,\n",
       "        0.043295  , 0.04349426, 0.04349527, 0.043391  , 0.04343009,\n",
       "        0.04352982, 0.04347346, 0.04350536, 0.04347707, 0.04347166]),\n",
       " 'rank_test_score': array([ 1,  2,  3,  6,  4,  9,  5,  7,  8, 10, 11, 13, 14, 15, 12, 16, 17,\n",
       "        19, 18, 20], dtype=int32),\n",
       " 'split0_train_score': array([0.76056175, 0.76196999, 0.76221603, 0.76247117, 0.76257535,\n",
       "        0.76254873, 0.76225904, 0.762208  , 0.76217293, 0.76217414,\n",
       "        0.76217307, 0.7622499 , 0.76222612, 0.76219481, 0.7622377 ,\n",
       "        0.76221683, 0.76224607, 0.76225006, 0.76229333, 0.76228297]),\n",
       " 'split1_train_score': array([0.75445492, 0.75532947, 0.75535966, 0.75519741, 0.75526622,\n",
       "        0.75515932, 0.75505174, 0.75508316, 0.75512013, 0.75505157,\n",
       "        0.75493806, 0.75484504, 0.75483652, 0.75474378, 0.75479602,\n",
       "        0.75475312, 0.75470108, 0.75475892, 0.75479163, 0.75471464]),\n",
       " 'split2_train_score': array([0.75185016, 0.75282979, 0.7530492 , 0.75279796, 0.75287984,\n",
       "        0.75264668, 0.752537  , 0.75261833, 0.75260357, 0.75275732,\n",
       "        0.7526798 , 0.75276246, 0.75266278, 0.75259854, 0.75255011,\n",
       "        0.75255702, 0.7525312 , 0.75251775, 0.75245785, 0.75239519]),\n",
       " 'split3_train_score': array([0.73367567, 0.73372485, 0.73386393, 0.73392009, 0.73391211,\n",
       "        0.73391337, 0.7338835 , 0.73387031, 0.73373228, 0.73376934,\n",
       "        0.73370345, 0.73379702, 0.7338544 , 0.73377523, 0.73372441,\n",
       "        0.73373028, 0.7336718 , 0.73365355, 0.73360117, 0.73361173]),\n",
       " 'split4_train_score': array([0.77228519, 0.77343602, 0.77410948, 0.77441658, 0.77445496,\n",
       "        0.77448878, 0.77450687, 0.77437834, 0.77446414, 0.77443537,\n",
       "        0.77442638, 0.77437888, 0.77433069, 0.77436732, 0.77431169,\n",
       "        0.77428026, 0.77425929, 0.77433043, 0.77429033, 0.77424691]),\n",
       " 'mean_train_score': array([0.75456554, 0.75545802, 0.75571966, 0.75576064, 0.75581769,\n",
       "        0.75575138, 0.75564763, 0.75563163, 0.75561861, 0.75563755,\n",
       "        0.75558415, 0.75560666, 0.7555821 , 0.75553593, 0.75552399,\n",
       "        0.7555075 , 0.75548189, 0.75550214, 0.75548686, 0.75545029]),\n",
       " 'std_train_score': array([0.01259931, 0.01299899, 0.0131554 , 0.01326031, 0.01328009,\n",
       "        0.01329799, 0.01328977, 0.01324857, 0.01331513, 0.01328866,\n",
       "        0.01331211, 0.01327297, 0.01324254, 0.01327965, 0.01328644,\n",
       "        0.01327368, 0.01329166, 0.0133181 , 0.01333072, 0.01331762])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best estimator was smallest so do new gridsearch for smaller C\n",
    "\n",
    "c_grid_2 = {'C': np.arange(0.01, 0.11, 0.01)}\n",
    "ridge_grid_2 = GridSearchCV(estimator=ridge, \n",
    "                          param_grid = c_grid_2,\n",
    "                          cv=5,\n",
    "                          verbose=0,\n",
    "                          scoring='average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=392, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='average_precision', verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_grid_2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.06999999999999999, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=392,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_grid_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.73762436, 1.89284334, 2.05412707, 2.29967799, 2.50113468,\n",
       "        2.70893517, 2.90344605, 2.64886312, 2.77842398, 3.31605511]),\n",
       " 'std_fit_time': array([0.39539328, 0.16635948, 0.28066621, 0.51324473, 0.46392762,\n",
       "        0.0916043 , 0.28247455, 0.28536984, 0.16901302, 0.24939569]),\n",
       " 'mean_score_time': array([0.02203422, 0.02207894, 0.02233801, 0.02312417, 0.02547317,\n",
       "        0.02549586, 0.02759008, 0.02396159, 0.02347236, 0.02729735]),\n",
       " 'std_score_time': array([0.00048139, 0.00095109, 0.00149391, 0.00192043, 0.00220765,\n",
       "        0.00380951, 0.00669325, 0.00172399, 0.00214286, 0.00315876]),\n",
       " 'param_C': masked_array(data=[0.01, 0.02, 0.03, 0.04, 0.05, 0.060000000000000005,\n",
       "                    0.06999999999999999, 0.08, 0.09, 0.09999999999999999],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.01},\n",
       "  {'C': 0.02},\n",
       "  {'C': 0.03},\n",
       "  {'C': 0.04},\n",
       "  {'C': 0.05},\n",
       "  {'C': 0.060000000000000005},\n",
       "  {'C': 0.06999999999999999},\n",
       "  {'C': 0.08},\n",
       "  {'C': 0.09},\n",
       "  {'C': 0.09999999999999999}],\n",
       " 'split0_test_score': array([0.73111957, 0.73135917, 0.72442919, 0.72263358, 0.7211533 ,\n",
       "        0.72195618, 0.72166528, 0.71995851, 0.71903144, 0.71872107]),\n",
       " 'split1_test_score': array([0.74359864, 0.751227  , 0.75780703, 0.75926857, 0.75906675,\n",
       "        0.7600377 , 0.75863783, 0.75878365, 0.75836729, 0.75784289]),\n",
       " 'split2_test_score': array([0.72126232, 0.73833696, 0.74425026, 0.74964529, 0.75291018,\n",
       "        0.75308293, 0.7560652 , 0.75666047, 0.75770481, 0.75819224]),\n",
       " 'split3_test_score': array([0.79959714, 0.80681853, 0.81060891, 0.81156832, 0.81194293,\n",
       "        0.81200656, 0.81202542, 0.81258876, 0.81254978, 0.81231487]),\n",
       " 'split4_test_score': array([0.67016639, 0.68516861, 0.68765014, 0.68937029, 0.68878638,\n",
       "        0.68822926, 0.68906685, 0.68863351, 0.68872519, 0.68835379]),\n",
       " 'mean_test_score': array([0.73314913, 0.74258234, 0.74494939, 0.7464975 , 0.7467722 ,\n",
       "        0.74706282, 0.74749241, 0.74732527, 0.747276  , 0.74708527]),\n",
       " 'std_test_score': array([0.04156131, 0.03909295, 0.04045052, 0.04059602, 0.04112103,\n",
       "        0.04126491, 0.04109201, 0.04164465, 0.04175728, 0.04182789]),\n",
       " 'rank_test_score': array([10,  9,  8,  7,  6,  5,  1,  2,  3,  4], dtype=int32),\n",
       " 'split0_train_score': array([0.74329628, 0.75090022, 0.75539084, 0.75710275, 0.75825491,\n",
       "        0.75955032, 0.75985708, 0.76033179, 0.76041343, 0.76056175]),\n",
       " 'split1_train_score': array([0.73929691, 0.74844896, 0.75091389, 0.75236294, 0.75294452,\n",
       "        0.75365739, 0.75407894, 0.75426074, 0.75441729, 0.75449035]),\n",
       " 'split2_train_score': array([0.73222101, 0.74299737, 0.74602799, 0.74811983, 0.74997038,\n",
       "        0.75051679, 0.75081714, 0.75130784, 0.75176384, 0.7518388 ]),\n",
       " 'split3_train_score': array([0.72114918, 0.72848227, 0.73089211, 0.73197209, 0.73279509,\n",
       "        0.73293645, 0.73318424, 0.7331769 , 0.73346644, 0.73363604]),\n",
       " 'split4_train_score': array([0.75594114, 0.76360869, 0.7667537 , 0.76840316, 0.76953945,\n",
       "        0.77056515, 0.77127701, 0.77154594, 0.77190237, 0.77229123]),\n",
       " 'mean_train_score': array([0.7383809 , 0.7468875 , 0.7499957 , 0.75159215, 0.75270087,\n",
       "        0.75344522, 0.75384288, 0.75412464, 0.75439267, 0.75456363]),\n",
       " 'std_train_score': array([0.01156061, 0.01141949, 0.01175986, 0.0119212 , 0.01198449,\n",
       "        0.01232554, 0.01245881, 0.01256018, 0.01255115, 0.01261459])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_grid_2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0       0    1\n",
      "Class             \n",
      "0      198992   28\n",
      "1         144  200\n",
      "True positives = 200\n",
      "True negatives = 198992\n",
      "False positives = 28\n",
      "False negatives = 144\n",
      "Sensitivity = 0.5813953488372093\n",
      "Specificity = 0.999859310622048\n"
     ]
    }
   ],
   "source": [
    "## Retrain model with best C\n",
    "\n",
    "ridge_2 = LogisticRegression(solver='liblinear',\n",
    "                            penalty='l2',\n",
    "                            random_state=392,\n",
    "                            C=0.07)\n",
    "\n",
    "ridge_2.fit(x_train, y_train)\n",
    "pred_y_ridge_2_train = ridge_2.predict(x_train)\n",
    "table_ridge_2_train = pd.crosstab(y_train, pred_y_ridge_2_train)\n",
    "print_results(table_ridge_2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_scores = cross_val_score(ridge, x_train, y_train, cv=5, scoring='average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_2_scores = cross_val_score(ridge_2, x_train, y_train, cv=5, scoring='average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "Mean = 0.7443274637158495\n",
      "[0.71009418 0.75066599 0.75927043 0.81359862 0.6880081 ]\n",
      "Ridge_2\n",
      "Mean = 0.7475472494589831\n",
      "[0.72172145 0.75859083 0.75635594 0.81200203 0.68906601]\n"
     ]
    }
   ],
   "source": [
    "## Print scores from original and updated ridge models\n",
    "\n",
    "print('Ridge')\n",
    "print('Mean =', ridge_scores.mean())\n",
    "print(ridge_scores)\n",
    "print('Ridge_2')\n",
    "print('Mean =', ridge_2_scores.mean())\n",
    "print(ridge_2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      0   1\n",
      "Class           \n",
      "0      85286   9\n",
      "1         55  93\n",
      "True positives = 93\n",
      "True negatives = 85286\n",
      "False positives = 9\n",
      "False negatives = 55\n",
      "Sensitivity = 0.6283783783783784\n",
      "Specificity = 0.9998944838501671\n"
     ]
    }
   ],
   "source": [
    "## Test data using updated ridge model\n",
    "\n",
    "pred_y_ridge_2_test = ridge_2.predict(x_test)\n",
    "table_ridge_2_test = pd.crosstab(y_test, pred_y_ridge_2_test)\n",
    "print_results(table_ridge_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models['ridge_2'] = table_ridge_2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso regression\n",
    "I am not going to try this type of model because the purpose is to identify as many of the fraudulent transactions as possible and this is likely to reduce this accuracy to get a faster model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=392,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_1 = SVC(random_state=392)\n",
    "svm_1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_svm_1 = svm_1.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_test = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid search for best gamma and cost\n",
    "\n",
    "gamma_c_grid = {'C': [0.001, 0.1, 10, 1000], 'gamma': [0.001, 0.1, 10, 1000]}\n",
    "\n",
    "#list(ParameterGrid(gamma_c_grid))[0]\n",
    "\n",
    "svm_grid = GridSearchCV(estimator=svm_test,\n",
    "                        param_grid = gamma_c_grid,\n",
    "                        cv=5,\n",
    "                        scoring='average_precision',\n",
    "                        verbose=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... C=0.001, gamma=0.001, score=0.6497632250801306, total=   6.1s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... C=0.001, gamma=0.001, score=0.6843215066698886, total=   6.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   20.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... C=0.001, gamma=0.001, score=0.6502690063560619, total=   5.7s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   30.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... C=0.001, gamma=0.001, score=0.603074719505198, total=   5.7s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   40.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... C=0.001, gamma=0.001, score=0.698280691286174, total=   5.7s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   50.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=0.001, gamma=0.1, score=0.7284243506985816, total=   6.3s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=0.001, gamma=0.1, score=0.7207795218011596, total=   6.3s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=0.001, gamma=0.1, score=0.6792065917665335, total=   6.7s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=0.001, gamma=0.1, score=0.6294883706836776, total=   6.5s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=0.001, gamma=0.1, score=0.6429584555211062, total=   6.2s\n",
      "[CV] C=0.001, gamma=10 ...............................................\n",
      "[CV] ...... C=0.001, gamma=10, score=0.2477517454916117, total=   8.3s\n",
      "[CV] C=0.001, gamma=10 ...............................................\n",
      "[CV] ...... C=0.001, gamma=10, score=0.1440711503068679, total=   8.8s\n",
      "[CV] C=0.001, gamma=10 ...............................................\n",
      "[CV] ...... C=0.001, gamma=10, score=0.2188167458387323, total=   8.4s\n",
      "[CV] C=0.001, gamma=10 ...............................................\n",
      "[CV] ..... C=0.001, gamma=10, score=0.12893384885684375, total=   8.9s\n",
      "[CV] C=0.001, gamma=10 ...............................................\n",
      "[CV] ..... C=0.001, gamma=10, score=0.16965854960060495, total=   8.9s\n",
      "[CV] C=0.001, gamma=1000 .............................................\n",
      "[CV] ... C=0.001, gamma=1000, score=0.04513509531163877, total=   7.3s\n",
      "[CV] C=0.001, gamma=1000 .............................................\n",
      "[CV] ... C=0.001, gamma=1000, score=0.03066664339331313, total=   7.5s\n",
      "[CV] C=0.001, gamma=1000 .............................................\n",
      "[CV] ... C=0.001, gamma=1000, score=0.11747296134841351, total=   7.8s\n",
      "[CV] C=0.001, gamma=1000 .............................................\n",
      "[CV] ... C=0.001, gamma=1000, score=0.07407027446666245, total=   9.2s\n",
      "[CV] C=0.001, gamma=1000 .............................................\n",
      "[CV] ... C=0.001, gamma=1000, score=0.07511045927141907, total=  11.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ..... C=0.1, gamma=0.001, score=0.6808020764774211, total= 9.2min\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ..... C=0.1, gamma=0.001, score=0.7022871762396653, total= 8.7min\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ..... C=0.1, gamma=0.001, score=0.6752767996024036, total= 9.6min\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ..... C=0.1, gamma=0.001, score=0.6937866593022385, total=  24.6s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ..... C=0.1, gamma=0.001, score=0.7061745965390569, total= 8.7min\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.6695132312217871, total=10.1min\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5243969031289791, total= 9.7min\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5750576140003917, total=10.6min\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ...... C=0.1, gamma=0.1, score=0.49030542397927074, total=11.1min\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.4655690006132297, total=12.7min\n",
      "[CV] C=0.1, gamma=10 .................................................\n",
      "[CV] ....... C=0.1, gamma=10, score=0.25914496088989036, total=12.2min\n",
      "[CV] C=0.1, gamma=10 .................................................\n",
      "[CV] ....... C=0.1, gamma=10, score=0.14478618398180784, total= 9.0min\n",
      "[CV] C=0.1, gamma=10 .................................................\n",
      "[CV] ........ C=0.1, gamma=10, score=0.2194671110988225, total= 8.9min\n",
      "[CV] C=0.1, gamma=10 .................................................\n",
      "[CV] ....... C=0.1, gamma=10, score=0.12847929128509544, total= 9.3min\n",
      "[CV] C=0.1, gamma=10 .................................................\n",
      "[CV] ......... C=0.1, gamma=10, score=0.172829826299047, total=13.3min\n",
      "[CV] C=0.1, gamma=1000 ...............................................\n",
      "[CV] ..... C=0.1, gamma=1000, score=0.04520469891398176, total= 8.6min\n",
      "[CV] C=0.1, gamma=1000 ...............................................\n",
      "[CV] .... C=0.1, gamma=1000, score=0.030734763159906132, total= 7.4min\n",
      "[CV] C=0.1, gamma=1000 ...............................................\n",
      "[CV] ..... C=0.1, gamma=1000, score=0.11753525906360164, total= 7.9min\n",
      "[CV] C=0.1, gamma=1000 ...............................................\n",
      "[CV] ..... C=0.1, gamma=1000, score=0.07411064076062256, total= 7.8min\n",
      "[CV] C=0.1, gamma=1000 ...............................................\n",
      "[CV] ...... C=0.1, gamma=1000, score=0.0751736334997513, total= 7.7min\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.7439685969255027, total=  31.2s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.7452405063861262, total=  29.8s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.8045197190333886, total=  27.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.8079598664777866, total=  31.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.7604024793175331, total=  25.8s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.6292529277357988, total=20.1min\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.4483412285064701, total=20.4min\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.5266679921160496, total=19.9min\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.4256455976020494, total=19.1min\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ....... C=10, gamma=0.1, score=0.39530875714556685, total=19.6min\n",
      "[CV] C=10, gamma=10 ..................................................\n",
      "[CV] ......... C=10, gamma=10, score=0.2612180754690334, total=60.1min\n",
      "[CV] C=10, gamma=10 ..................................................\n",
      "[CV] ........ C=10, gamma=10, score=0.12887681028905215, total=59.9min\n",
      "[CV] C=10, gamma=10 ..................................................\n",
      "[CV] ......... C=10, gamma=10, score=0.2202439984740518, total=65.2min\n",
      "[CV] C=10, gamma=10 ..................................................\n",
      "[CV] ........ C=10, gamma=10, score=0.12941066219035138, total=59.0min\n",
      "[CV] C=10, gamma=10 ..................................................\n",
      "[CV] ........ C=10, gamma=10, score=0.17358574282565248, total=66.2min\n",
      "[CV] C=10, gamma=1000 ................................................\n",
      "[CV] ..... C=10, gamma=1000, score=0.045304947094690455, total=40.1min\n",
      "[CV] C=10, gamma=1000 ................................................\n",
      "[CV] ..... C=10, gamma=1000, score=0.030835109719875044, total=40.3min\n",
      "[CV] C=10, gamma=1000 ................................................\n",
      "[CV] ...... C=10, gamma=1000, score=0.13208863194302128, total=39.1min\n",
      "[CV] C=10, gamma=1000 ................................................\n",
      "[CV] ...... C=10, gamma=1000, score=0.08866428339367805, total=39.6min\n",
      "[CV] C=10, gamma=1000 ................................................\n",
      "[CV] ...... C=10, gamma=1000, score=0.07526763050435935, total=39.5min\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] ..... C=1000, gamma=0.001, score=0.706311611539118, total=  34.7s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .... C=1000, gamma=0.001, score=0.7026547647433197, total=  36.4s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .... C=1000, gamma=0.001, score=0.7569979907996004, total=  44.9s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .... C=1000, gamma=0.001, score=0.6962928126832376, total=  38.7s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .... C=1000, gamma=0.001, score=0.7284748151026184, total=  30.4s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ...... C=1000, gamma=0.1, score=0.6193423889162916, total=21.7min\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ..... C=1000, gamma=0.1, score=0.40986043880974393, total=20.8min\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=1000, gamma=0.1, score=0.5057103705844724, total=21.5min\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ...... C=1000, gamma=0.1, score=0.4068618341855855, total=20.6min\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ...... C=1000, gamma=0.1, score=0.3868884905397954, total=29.5min\n",
      "[CV] C=1000, gamma=10 ................................................\n",
      "[CV] ....... C=1000, gamma=10, score=0.2612180739819179, total=59.8min\n",
      "[CV] C=1000, gamma=10 ................................................\n",
      "[CV] ....... C=1000, gamma=10, score=0.1288766402950645, total=62.2min\n",
      "[CV] C=1000, gamma=10 ................................................\n",
      "[CV] ...... C=1000, gamma=10, score=0.22024400046108872, total=65.6min\n",
      "[CV] C=1000, gamma=10 ................................................\n",
      "[CV] ...... C=1000, gamma=10, score=0.12941066219035138, total=58.7min\n",
      "[CV] C=1000, gamma=10 ................................................\n",
      "[CV] ...... C=1000, gamma=10, score=0.17358574282565248, total=75.1min\n",
      "[CV] C=1000, gamma=1000 ..............................................\n",
      "[CV] ... C=1000, gamma=1000, score=0.045304947094690455, total=58.4min\n",
      "[CV] C=1000, gamma=1000 ..............................................\n",
      "[CV] ... C=1000, gamma=1000, score=0.030835109719875044, total=40.8min\n",
      "[CV] C=1000, gamma=1000 ..............................................\n",
      "[CV] .... C=1000, gamma=1000, score=0.13208863194302128, total=39.6min\n",
      "[CV] C=1000, gamma=1000 ..............................................\n",
      "[CV] .... C=1000, gamma=1000, score=0.08866428339367805, total=40.4min\n",
      "[CV] C=1000, gamma=1000 ..............................................\n",
      "[CV] .... C=1000, gamma=1000, score=0.07526763050435935, total=43.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 1824.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.1, 10, 1000], 'gamma': [0.001, 0.1, 10, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='average_precision', verbose=10)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This took approx 2 days to run\n",
    "## Uncomment at your peril!\n",
    "\n",
    "#svm_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.001}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "## It says C=10, gamma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([   4.80634828,    5.24839916,    7.48941479,    7.39845738,\n",
       "         437.0103704 ,  612.07589846,  573.46160698,  426.74389544,\n",
       "          27.22044768, 1138.92231126, 3500.13498344, 2190.34356165,\n",
       "          36.0904736 , 1320.90620022, 3615.83455925, 2476.39578581]),\n",
       " 'std_fit_time': array([1.56158862e-01, 1.84697099e-01, 2.13974943e-01, 1.22168599e+00,\n",
       "        2.08337177e+02, 5.86535356e+01, 1.04725195e+02, 2.49925585e+01,\n",
       "        2.24917085e+00, 2.55177895e+01, 1.80068848e+02, 2.72830854e+01,\n",
       "        4.77253592e+00, 2.02150445e+02, 3.28029572e+02, 4.22606294e+02]),\n",
       " 'mean_score_time': array([  1.04397001,   1.139464  ,   1.17941804,   1.14639287,\n",
       "          2.21277194,  38.06273465,  58.15876327,  45.07555666,\n",
       "          1.83386159,  50.75950675, 224.31034989, 192.2588932 ,\n",
       "          0.9329278 ,  48.14598632, 240.80545216, 193.99472117]),\n",
       " 'std_score_time': array([3.67327535e-02, 2.32790818e-02, 5.79756511e-02, 1.63460145e-01,\n",
       "        4.77937310e-02, 4.87094270e+00, 8.27675494e+00, 1.24931284e+00,\n",
       "        2.17120243e-02, 1.85843338e+00, 1.47733148e+00, 1.29181974e-01,\n",
       "        3.55942354e-02, 8.59242667e-01, 2.93794539e+01, 3.62223742e+00]),\n",
       " 'param_C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.1, 0.1, 0.1, 0.1, 10, 10,\n",
       "                    10, 10, 1000, 1000, 1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.001, 0.1, 10, 1000, 0.001, 0.1, 10, 1000, 0.001, 0.1,\n",
       "                    10, 1000, 0.001, 0.1, 10, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.001, 'gamma': 0.001},\n",
       "  {'C': 0.001, 'gamma': 0.1},\n",
       "  {'C': 0.001, 'gamma': 10},\n",
       "  {'C': 0.001, 'gamma': 1000},\n",
       "  {'C': 0.1, 'gamma': 0.001},\n",
       "  {'C': 0.1, 'gamma': 0.1},\n",
       "  {'C': 0.1, 'gamma': 10},\n",
       "  {'C': 0.1, 'gamma': 1000},\n",
       "  {'C': 10, 'gamma': 0.001},\n",
       "  {'C': 10, 'gamma': 0.1},\n",
       "  {'C': 10, 'gamma': 10},\n",
       "  {'C': 10, 'gamma': 1000},\n",
       "  {'C': 1000, 'gamma': 0.001},\n",
       "  {'C': 1000, 'gamma': 0.1},\n",
       "  {'C': 1000, 'gamma': 10},\n",
       "  {'C': 1000, 'gamma': 1000}],\n",
       " 'split0_test_score': array([0.64976323, 0.72842435, 0.24775175, 0.0451351 , 0.68080208,\n",
       "        0.66951323, 0.25914496, 0.0452047 , 0.7439686 , 0.62925293,\n",
       "        0.26121808, 0.04530495, 0.70631161, 0.61934239, 0.26121807,\n",
       "        0.04530495]),\n",
       " 'split1_test_score': array([0.68432151, 0.72077952, 0.14407115, 0.03066664, 0.70228718,\n",
       "        0.5243969 , 0.14478618, 0.03073476, 0.74524051, 0.44834123,\n",
       "        0.12887681, 0.03083511, 0.70265476, 0.40986044, 0.12887664,\n",
       "        0.03083511]),\n",
       " 'split2_test_score': array([0.65026901, 0.67920659, 0.21881675, 0.11747296, 0.6752768 ,\n",
       "        0.57505761, 0.21946711, 0.11753526, 0.80451972, 0.52666799,\n",
       "        0.220244  , 0.13208863, 0.75699799, 0.50571037, 0.220244  ,\n",
       "        0.13208863]),\n",
       " 'split3_test_score': array([0.60307472, 0.62948837, 0.12893385, 0.07407027, 0.69378666,\n",
       "        0.49030542, 0.12847929, 0.07411064, 0.80795987, 0.4256456 ,\n",
       "        0.12941066, 0.08866428, 0.69629281, 0.40686183, 0.12941066,\n",
       "        0.08866428]),\n",
       " 'split4_test_score': array([0.69828069, 0.64295846, 0.16965855, 0.07511046, 0.7061746 ,\n",
       "        0.465569  , 0.17282983, 0.07517363, 0.76040248, 0.39530876,\n",
       "        0.17358574, 0.07526763, 0.72847482, 0.38688849, 0.17358574,\n",
       "        0.07526763]),\n",
       " 'mean_test_score': array([0.65714162, 0.68017164, 0.18184647, 0.06849105, 0.69166539,\n",
       "        0.54496883, 0.18494154, 0.06855177, 0.77241829, 0.48504375,\n",
       "        0.1826671 , 0.07443212, 0.71814635, 0.4657331 , 0.18266707,\n",
       "        0.07443212]),\n",
       " 'std_test_score': array([0.03303349, 0.03982932, 0.0449124 , 0.02983414, 0.01195353,\n",
       "        0.07229418, 0.04826044, 0.02983074, 0.02823515, 0.08420977,\n",
       "        0.05175801, 0.03543063, 0.02224304, 0.08717578, 0.05175805,\n",
       "        0.03543063]),\n",
       " 'rank_test_score': array([ 5,  4, 12, 16,  3,  6,  9, 15,  1,  7, 10, 13,  2,  8, 11, 13],\n",
       "       dtype=int32),\n",
       " 'split0_train_score': array([0.70113388, 0.94555832, 0.99636996, 1.        , 0.76239409,\n",
       "        0.99636227, 1.        , 1.        , 0.8851276 , 1.        ,\n",
       "        1.        , 1.        , 0.96765433, 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " 'split1_train_score': array([0.6699128 , 0.94920019, 0.99636996, 1.        , 0.76885487,\n",
       "        0.99634577, 1.        , 1.        , 0.89721782, 1.        ,\n",
       "        1.        , 1.        , 0.9706196 , 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " 'split2_train_score': array([0.70333685, 0.94922013, 0.99636996, 1.        , 0.77775367,\n",
       "        0.99622512, 1.        , 1.        , 0.88630811, 1.        ,\n",
       "        1.        , 1.        , 0.97212636, 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " 'split3_train_score': array([0.66716585, 0.94557106, 1.        , 1.        , 0.76352724,\n",
       "        1.        , 1.        , 1.        , 0.8779368 , 1.        ,\n",
       "        1.        , 1.        , 0.96975449, 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " 'split4_train_score': array([0.68429724, 0.9565065 , 1.        , 1.        , 0.7522756 ,\n",
       "        0.99624996, 1.        , 1.        , 0.89276497, 1.        ,\n",
       "        1.        , 1.        , 0.9719835 , 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " 'mean_train_score': array([0.68516933, 0.94921124, 0.99782198, 1.        , 0.7649611 ,\n",
       "        0.99703663, 1.        , 1.        , 0.88787106, 1.        ,\n",
       "        1.        , 1.        , 0.97042766, 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " 'std_train_score': array([1.51166999e-02, 3.99539106e-03, 1.77834805e-03, 0.00000000e+00,\n",
       "        8.34719841e-03, 1.48263293e-03, 9.93013661e-17, 0.00000000e+00,\n",
       "        6.63281423e-03, 0.00000000e+00, 1.71995011e-16, 0.00000000e+00,\n",
       "        1.64241068e-03, 0.00000000e+00, 1.40433339e-16, 0.00000000e+00])}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65714162, 0.68017164, 0.18184647, 0.06849105],\n",
       "       [0.69166539, 0.54496883, 0.18494154, 0.06855177],\n",
       "       [0.77241829, 0.48504375, 0.1826671 , 0.07443212],\n",
       "       [0.71814635, 0.4657331 , 0.18266707, 0.07443212]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid.cv_results_['mean_test_score'].reshape(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma0_001</th>\n",
       "      <th>gamma0_1</th>\n",
       "      <th>gamma10</th>\n",
       "      <th>gamma1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C0_001</th>\n",
       "      <td>0.657142</td>\n",
       "      <td>0.680172</td>\n",
       "      <td>0.181846</td>\n",
       "      <td>0.068491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C0_1</th>\n",
       "      <td>0.691665</td>\n",
       "      <td>0.544969</td>\n",
       "      <td>0.184942</td>\n",
       "      <td>0.068552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C10</th>\n",
       "      <td>0.772418</td>\n",
       "      <td>0.485044</td>\n",
       "      <td>0.182667</td>\n",
       "      <td>0.074432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000</th>\n",
       "      <td>0.718146</td>\n",
       "      <td>0.465733</td>\n",
       "      <td>0.182667</td>\n",
       "      <td>0.074432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gamma0_001  gamma0_1   gamma10  gamma1000\n",
       "C0_001    0.657142  0.680172  0.181846   0.068491\n",
       "C0_1      0.691665  0.544969  0.184942   0.068552\n",
       "C10       0.772418  0.485044  0.182667   0.074432\n",
       "C1000     0.718146  0.465733  0.182667   0.074432"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_results = pd.DataFrame(\n",
    "    data=svm_grid.cv_results_['mean_test_score'].reshape(4, 4),\n",
    "    columns=['gamma0_001', 'gamma0_1', 'gamma10', 'gamma1000'],\n",
    "    index=['C0_001', 'C0_1', 'C10', 'C1000']\n",
    ")\n",
    "\n",
    "svm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid search for improved cost for gamma = 0.001\n",
    "\n",
    "svm_3 = SVC(random_state=392, gamma=0.001)\n",
    "\n",
    "c_grid_3 = {'C': [1, 10, 50, 100]}\n",
    "\n",
    "#list(ParameterGrid(gamma_c_grid))[0]\n",
    "\n",
    "svm_3_grid = GridSearchCV(estimator=svm_3,\n",
    "                        param_grid = c_grid_3,\n",
    "                        cv=5,\n",
    "                        scoring='average_precision',\n",
    "                        verbose=10,\n",
    "                         n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=2)]: Done  20 out of  20 | elapsed: 19.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  20 out of  20 | elapsed: 19.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=392, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'C': [1, 10, 50, 100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='average_precision',\n",
       "       verbose=10)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_3_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 50}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_3_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([353.11130433,  30.40843024,  19.50908203,  22.42353144]),\n",
       " 'std_fit_time': array([265.09691858,   3.032128  ,   2.28867347,   3.53267575]),\n",
       " 'mean_score_time': array([2.44607282, 2.17240744, 1.06291895, 1.10524659]),\n",
       " 'std_score_time': array([0.16899079, 0.12701307, 0.05571986, 0.05148165]),\n",
       " 'param_C': masked_array(data=[1, 10, 50, 100],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1}, {'C': 10}, {'C': 50}, {'C': 100}],\n",
       " 'split0_test_score': array([0.71144109, 0.7439686 , 0.77161186, 0.75238456]),\n",
       " 'split1_test_score': array([0.70099704, 0.74524051, 0.75991273, 0.75703785]),\n",
       " 'split2_test_score': array([0.74282888, 0.80451972, 0.79799506, 0.78325256]),\n",
       " 'split3_test_score': array([0.76494524, 0.80795987, 0.80424284, 0.78767044]),\n",
       " 'split4_test_score': array([0.74623155, 0.76040248, 0.74830239, 0.72880169]),\n",
       " 'mean_test_score': array([0.73328869, 0.77241829, 0.77641312, 0.76182958]),\n",
       " 'std_test_score': array([0.02358283, 0.02823515, 0.02156754, 0.02158559]),\n",
       " 'rank_test_score': array([4, 2, 1, 3], dtype=int32),\n",
       " 'split0_train_score': array([0.81650945, 0.8851276 , 0.91947734, 0.93273742]),\n",
       " 'split1_train_score': array([0.83521871, 0.89721782, 0.91747523, 0.93484503]),\n",
       " 'split2_train_score': array([0.82093317, 0.88630811, 0.92228178, 0.93124532]),\n",
       " 'split3_train_score': array([0.81028479, 0.8779368 , 0.92021454, 0.93198973]),\n",
       " 'split4_train_score': array([0.81535983, 0.89276497, 0.92446038, 0.93341278]),\n",
       " 'mean_train_score': array([0.81966119, 0.88787106, 0.92078186, 0.93284606]),\n",
       " 'std_train_score': array([0.00848536, 0.00663281, 0.00239745, 0.00123487])}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_3_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      0    1\n",
      "Class            \n",
      "0      85287    8\n",
      "1         34  114\n",
      "True positives = 114\n",
      "True negatives = 85287\n",
      "False positives = 8\n",
      "False negatives = 34\n",
      "Sensitivity = 0.7702702702702703\n",
      "Specificity = 0.9999062078668152\n"
     ]
    }
   ],
   "source": [
    "## Retrain on best parameters\n",
    "\n",
    "## Test on test set for comparison to other models\n",
    "\n",
    "svm_4 = SVC(random_state = 392, C=50, gamma=0.001)\n",
    "svm_4.fit(x_train, y_train)\n",
    "y_pred_svm_4 = svm_4.predict(x_test)\n",
    "table_svm_4_test = pd.crosstab(y_test, y_pred_svm_4)\n",
    "print_results(table_svm_4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models['svm_4'] = table_svm_4_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_1 = KNeighborsClassifier()\n",
    "\n",
    "n_weight_grid_1 = {'n_neighbors': [3, 5, 10], 'weights': ['uniform', 'distance']}\n",
    "\n",
    "knn_1_grid = GridSearchCV(estimator=knn_1,\n",
    "                         param_grid = n_weight_grid_1,\n",
    "                         cv=5,\n",
    "                         scoring='average_precision', \n",
    "                         verbose=10,\n",
    "                         n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=uniform, score=0.7379237209265016, total=  33.5s\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=uniform, score=0.655385937202625, total=  30.6s\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=uniform, score=0.6855178461988348, total=  36.3s\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=uniform, score=0.6055221503134315, total=  33.1s\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=uniform, score=0.6954893126033999, total=  33.5s\n",
      "[CV] n_neighbors=3, weights=distance .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=distance, score=0.7737990963471055, total=  32.4s\n",
      "[CV] n_neighbors=3, weights=distance .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 14.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=distance, score=0.6737796784929289, total=  31.1s\n",
      "[CV] n_neighbors=3, weights=distance .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 17.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=distance, score=0.7069535761623345, total=  32.8s\n",
      "[CV] n_neighbors=3, weights=distance .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 19.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=distance, score=0.6242495965901359, total= 2.8min\n",
      "[CV] n_neighbors=3, weights=distance .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 24.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=distance, score=0.7167182483037509, total=  37.6s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.7258460065508769, total=  33.8s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.6585924492062369, total=  41.7s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.6814653350005783, total=  44.0s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.6341746657321272, total=  40.7s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.6899697134593945, total=  40.4s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.7630935255696485, total=  37.7s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.6825420135758006, total=  36.2s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.7256416346416743, total=  37.6s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.6542482213664851, total=  34.9s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.7144002210475868, total=  44.6s\n",
      "[CV] n_neighbors=10, weights=uniform .................................\n",
      "[CV]  n_neighbors=10, weights=uniform, score=0.7182018159539567, total=  47.8s\n",
      "[CV] n_neighbors=10, weights=uniform .................................\n",
      "[CV]  n_neighbors=10, weights=uniform, score=0.6423751329270808, total=  47.7s\n",
      "[CV] n_neighbors=10, weights=uniform .................................\n",
      "[CV]  n_neighbors=10, weights=uniform, score=0.6695433457142658, total= 1.0min\n",
      "[CV] n_neighbors=10, weights=uniform .................................\n",
      "[CV]  n_neighbors=10, weights=uniform, score=0.6168821977206986, total=  44.0s\n",
      "[CV] n_neighbors=10, weights=uniform .................................\n",
      "[CV]  n_neighbors=10, weights=uniform, score=0.6639226101870217, total=  43.9s\n",
      "[CV] n_neighbors=10, weights=distance ................................\n",
      "[CV]  n_neighbors=10, weights=distance, score=0.7686649394900549, total=  45.1s\n",
      "[CV] n_neighbors=10, weights=distance ................................\n",
      "[CV]  n_neighbors=10, weights=distance, score=0.6771219736420517, total=  48.2s\n",
      "[CV] n_neighbors=10, weights=distance ................................\n",
      "[CV]  n_neighbors=10, weights=distance, score=0.7247458779027995, total=  46.9s\n",
      "[CV] n_neighbors=10, weights=distance ................................\n",
      "[CV]  n_neighbors=10, weights=distance, score=0.653956672607644, total=  41.9s\n",
      "[CV] n_neighbors=10, weights=distance ................................\n",
      "[CV]  n_neighbors=10, weights=distance, score=0.7024901694891625, total=  47.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 94.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=1,\n",
       "       param_grid={'n_neighbors': [3, 5, 10], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='average_precision', verbose=10)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_1_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 5, 'weights': 'distance'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_1_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.63130302, 0.67151294, 0.62936387, 0.61389456, 0.64162002,\n",
       "        0.69184804]),\n",
       " 'std_fit_time': array([0.04316171, 0.04513785, 0.05869786, 0.03306693, 0.14315167,\n",
       "        0.10888712]),\n",
       " 'mean_score_time': array([32.73997602, 59.58899961, 39.49200521, 37.59378581, 48.37414436,\n",
       "        45.21985936]),\n",
       " 'std_score_time': array([ 1.79765952, 53.68606934,  3.34827961,  3.33133593,  6.43986566,\n",
       "         2.36656492]),\n",
       " 'param_n_neighbors': masked_array(data=[3, 3, 5, 5, 10, 10],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_weights': masked_array(data=['uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance'],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_neighbors': 3, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 3, 'weights': 'distance'},\n",
       "  {'n_neighbors': 5, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 5, 'weights': 'distance'},\n",
       "  {'n_neighbors': 10, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 10, 'weights': 'distance'}],\n",
       " 'split0_test_score': array([0.73792372, 0.7737991 , 0.72584601, 0.76309353, 0.71820182,\n",
       "        0.76866494]),\n",
       " 'split1_test_score': array([0.65538594, 0.67377968, 0.65859245, 0.68254201, 0.64237513,\n",
       "        0.67712197]),\n",
       " 'split2_test_score': array([0.68551785, 0.70695358, 0.68146534, 0.72564163, 0.66954335,\n",
       "        0.72474588]),\n",
       " 'split3_test_score': array([0.60552215, 0.6242496 , 0.63417467, 0.65424822, 0.6168822 ,\n",
       "        0.65395667]),\n",
       " 'split4_test_score': array([0.69548931, 0.71671825, 0.68996971, 0.71440022, 0.66392261,\n",
       "        0.70249017]),\n",
       " 'mean_test_score': array([0.6759677 , 0.69909995, 0.67800957, 0.70798509, 0.66218501,\n",
       "        0.70539594]),\n",
       " 'std_test_score': array([0.04403878, 0.04938784, 0.03079563, 0.03721527, 0.03358527,\n",
       "        0.03957596]),\n",
       " 'rank_test_score': array([5, 3, 4, 1, 6, 2], dtype=int32),\n",
       " 'split0_train_score': array([0.92481175, 1.        , 0.88982754, 1.        , 0.82694353,\n",
       "        1.        ]),\n",
       " 'split1_train_score': array([0.93196454, 1.        , 0.89247024, 1.        , 0.82904073,\n",
       "        1.        ]),\n",
       " 'split2_train_score': array([0.9365051 , 1.        , 0.90070329, 1.        , 0.83078216,\n",
       "        1.        ]),\n",
       " 'split3_train_score': array([0.93615438, 1.        , 0.89587944, 1.        , 0.83912771,\n",
       "        1.        ]),\n",
       " 'split4_train_score': array([0.93490935, 1.        , 0.89398734, 1.        , 0.83183451,\n",
       "        1.        ]),\n",
       " 'mean_train_score': array([0.93286903, 1.        , 0.89457357, 1.        , 0.83154573,\n",
       "        1.        ]),\n",
       " 'std_train_score': array([0.00433394, 0.        , 0.00364887, 0.        , 0.00413783,\n",
       "        0.        ])}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_1_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      0   1\n",
      "Class           \n",
      "0      85291   4\n",
      "1         49  99\n",
      "True positives = 99\n",
      "True negatives = 85291\n",
      "False positives = 4\n",
      "False negatives = 49\n",
      "Sensitivity = 0.668918918918919\n",
      "Specificity = 0.9999531039334076\n"
     ]
    }
   ],
   "source": [
    "## Retrain on best params and test on test set for comparison\n",
    "\n",
    "knn_2 = KNeighborsClassifier(n_neighbors =5 , weights='distance')\n",
    "knn_2.fit(x_train, y_train)\n",
    "pred_y_knn_2 = knn_2.predict(x_test)\n",
    "table_knn_2_test = pd.crosstab(y_test, pred_y_knn_2)\n",
    "print_results(table_knn_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models['knn_2'] = table_knn_2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_1 = RandomForestClassifier(n_estimators=10,\n",
    "                               random_state=392,\n",
    "                               verbose=2,\n",
    "                               n_jobs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_1_params = {'max_depth': [5, 10, 30], 'max_features': [2, 5, 10]}\n",
    "\n",
    "rfc_1_grid = GridSearchCV(rfc_1,\n",
    "                         rfc_1_params,\n",
    "                         scoring='average_precision',\n",
    "                         cv=5,\n",
    "                         verbose=10,\n",
    "                         n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=2)]: Done  45 out of  45 | elapsed:  3.0min finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10building tree 2 of 10\n",
      "\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=2,\n",
       "            oob_score=False, random_state=392, verbose=2, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'max_depth': [5, 10, 30], 'max_features': [2, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='average_precision', verbose=10)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_1_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'max_features': 5}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_1_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 1.98929162,  3.71066256,  6.60944891,  2.90821157,  6.95738678,\n",
       "        12.64408236,  3.73599405,  9.11913567, 17.707236  ]),\n",
       " 'std_fit_time': array([0.08585694, 0.21263038, 0.38901156, 0.18392263, 0.39752634,\n",
       "        1.14144236, 0.09954115, 0.65687826, 2.17830605]),\n",
       " 'mean_score_time': array([0.12434034, 0.12443404, 0.12435403, 0.13279471, 0.12615361,\n",
       "        0.12354245, 0.11877818, 0.12283287, 0.12195759]),\n",
       " 'std_score_time': array([0.00329677, 0.00303242, 0.0027887 , 0.00508212, 0.00342836,\n",
       "        0.00295814, 0.00179566, 0.00189039, 0.00126607]),\n",
       " 'param_max_depth': masked_array(data=[5, 5, 5, 10, 10, 10, 30, 30, 30],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[2, 5, 10, 2, 5, 10, 2, 5, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 5, 'max_features': 2},\n",
       "  {'max_depth': 5, 'max_features': 5},\n",
       "  {'max_depth': 5, 'max_features': 10},\n",
       "  {'max_depth': 10, 'max_features': 2},\n",
       "  {'max_depth': 10, 'max_features': 5},\n",
       "  {'max_depth': 10, 'max_features': 10},\n",
       "  {'max_depth': 30, 'max_features': 2},\n",
       "  {'max_depth': 30, 'max_features': 5},\n",
       "  {'max_depth': 30, 'max_features': 10}],\n",
       " 'split0_test_score': array([0.77751603, 0.79418335, 0.81365566, 0.80084553, 0.82695877,\n",
       "        0.83413061, 0.8100413 , 0.8034414 , 0.83206364]),\n",
       " 'split1_test_score': array([0.75048527, 0.80392515, 0.81432543, 0.82512278, 0.83004774,\n",
       "        0.84303517, 0.82242588, 0.82421423, 0.83969638]),\n",
       " 'split2_test_score': array([0.80345855, 0.8215507 , 0.81168561, 0.82853889, 0.83233087,\n",
       "        0.81515851, 0.82083501, 0.83252749, 0.81333615]),\n",
       " 'split3_test_score': array([0.81181904, 0.8043949 , 0.78811065, 0.76758872, 0.81762133,\n",
       "        0.77956695, 0.76856014, 0.81109058, 0.75658448]),\n",
       " 'split4_test_score': array([0.73899897, 0.75820957, 0.75867099, 0.77249954, 0.76997698,\n",
       "        0.77455472, 0.77474265, 0.75774975, 0.76701008]),\n",
       " 'mean_test_score': array([0.77645576, 0.79645293, 0.79728986, 0.79891922, 0.81538736,\n",
       "        0.80928937, 0.79932112, 0.80580493, 0.80173832]),\n",
       " 'std_test_score': array([0.02848964, 0.02105463, 0.02163764, 0.02548435, 0.02325064,\n",
       "        0.02785757, 0.02307352, 0.02606063, 0.03388176]),\n",
       " 'rank_test_score': array([9, 8, 7, 6, 1, 2, 5, 3, 4], dtype=int32),\n",
       " 'split0_train_score': array([0.81477403, 0.83221255, 0.84070373, 0.90547486, 0.94183334,\n",
       "        0.92703169, 0.99968569, 0.99942026, 0.99929535]),\n",
       " 'split1_train_score': array([0.79616828, 0.83013828, 0.83873035, 0.92141547, 0.92292094,\n",
       "        0.92520834, 0.99974199, 0.99894008, 0.99950451]),\n",
       " 'split2_train_score': array([0.81122235, 0.83188082, 0.84444815, 0.91962488, 0.92089876,\n",
       "        0.91907154, 0.99910378, 0.99952894, 0.99946142]),\n",
       " 'split3_train_score': array([0.82038292, 0.838973  , 0.83555468, 0.90127209, 0.91717264,\n",
       "        0.92599811, 0.99943009, 0.99951156, 0.999632  ]),\n",
       " 'split4_train_score': array([0.82808428, 0.85748954, 0.85238875, 0.91551702, 0.94450957,\n",
       "        0.93984462, 0.99927266, 0.99944498, 0.99925952]),\n",
       " 'mean_train_score': array([0.81412637, 0.83813884, 0.84236513, 0.91266087, 0.92946705,\n",
       "        0.92743086, 0.99944684, 0.99936916, 0.99943056]),\n",
       " 'std_train_score': array([0.01063309, 0.01013349, 0.00578215, 0.00793273, 0.01137209,\n",
       "        0.00679899, 0.00024186, 0.0002183 , 0.0001375 ])}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_1_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxfeat2</th>\n",
       "      <th>maxfeat5</th>\n",
       "      <th>maxfeat10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maxdepth5</th>\n",
       "      <td>0.776456</td>\n",
       "      <td>0.796453</td>\n",
       "      <td>0.797290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxdepth10</th>\n",
       "      <td>0.798919</td>\n",
       "      <td>0.815387</td>\n",
       "      <td>0.809289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxdepth30</th>\n",
       "      <td>0.799321</td>\n",
       "      <td>0.805805</td>\n",
       "      <td>0.801738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            maxfeat2  maxfeat5  maxfeat10\n",
       "maxdepth5   0.776456  0.796453   0.797290\n",
       "maxdepth10  0.798919  0.815387   0.809289\n",
       "maxdepth30  0.799321  0.805805   0.801738"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_1_results = pd.DataFrame(\n",
    "    data=rfc_1_grid.cv_results_['mean_test_score'].reshape(3, 3),\n",
    "    columns=['maxfeat2', 'maxfeat5', 'maxfeat10'],\n",
    "    index=['maxdepth5', 'maxdepth10', 'maxdepth30']\n",
    ")\n",
    "\n",
    "rfc_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      0    1\n",
      "Class            \n",
      "0      85289    6\n",
      "1         30  118\n",
      "True positives = 118\n",
      "True negatives = 85289\n",
      "False positives = 6\n",
      "False negatives = 30\n",
      "Sensitivity = 0.7972972972972973\n",
      "Specificity = 0.9999296559001114\n"
     ]
    }
   ],
   "source": [
    "## Retrain with best parameters and test on test set\n",
    "\n",
    "rfc_2 = RandomForestClassifier(n_estimators=10,\n",
    "                               random_state=392,\n",
    "                               max_depth=10,\n",
    "                               max_features=5)\n",
    "\n",
    "rfc_2.fit(x_train, y_train)\n",
    "pred_y_rfc_2 = rfc_2.predict(x_test)\n",
    "table_rfc_2_test = pd.crosstab(y_test, pred_y_rfc_2)\n",
    "print_results(table_rfc_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models['rfc_2'] = table_rfc_2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_1 = GradientBoostingClassifier(loss='deviance',\n",
    "                                 max_depth=5,\n",
    "                                random_state=392,\n",
    "                                verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_1_params = {'loss': ['deviance', 'exponential'], 'max_depth': [5, 10, 20]}\n",
    "\n",
    "gbc_1_grid = GridSearchCV(gbc_1,\n",
    "                          gbc_1_params,\n",
    "                          scoring='average_precision',\n",
    "                          cv=5,\n",
    "                          verbose=10,\n",
    "                          n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=2)]: Done  30 out of  30 | elapsed: 48.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0773            2.06m\n",
      "         2           0.0720            2.08m\n",
      "         3           0.0675            2.04m\n",
      "         4           0.0630            2.03m\n",
      "         5           0.0592            2.00m\n",
      "         6           0.0561            2.05m\n",
      "         7           0.0529            2.06m\n",
      "         8           0.0502            2.08m\n",
      "         9           0.0478            2.08m\n",
      "        10           0.0454            2.09m\n",
      "        11           0.0437            2.07m\n",
      "        12           0.0420            2.06m\n",
      "        13           0.0403            2.04m\n",
      "        14           0.0390            2.02m\n",
      "        15           0.0377            2.01m\n",
      "        16           0.0365            1.99m\n",
      "        17           0.0355            1.98m\n",
      "        18           0.0346            1.95m\n",
      "        19           0.0338            1.93m\n",
      "        20           0.0330            1.92m\n",
      "        21           0.0324            1.89m\n",
      "        22           0.0317            1.88m\n",
      "        23           0.0309            1.87m\n",
      "        24           0.0304            1.84m\n",
      "        25           0.0298            1.82m\n",
      "        26           0.0292            1.80m\n",
      "        27           0.0286            1.78m\n",
      "        28           0.0278            1.76m\n",
      "        29           0.0271            1.74m\n",
      "        30           0.0265            1.72m\n",
      "        31           0.0259            1.71m\n",
      "        32           0.0253            1.69m\n",
      "        33           0.0250            1.67m\n",
      "        34           0.0247            1.65m\n",
      "        35           0.0241            1.63m\n",
      "        36           0.0236            1.61m\n",
      "        37           0.0231            1.58m\n",
      "        38           0.0225            1.56m\n",
      "        39           0.0220            1.54m\n",
      "        40           0.0217            1.51m\n",
      "        41           0.0214            1.48m\n",
      "        42           0.0210            1.45m\n",
      "        43           0.0206            1.43m\n",
      "        44           0.0201            1.41m\n",
      "        45           0.0196            1.38m\n",
      "        46           0.0192            1.36m\n",
      "        47           0.0189            1.34m\n",
      "        48           0.0184            1.32m\n",
      "        49           0.0183            1.30m\n",
      "        50           0.0179            1.28m\n",
      "        51           0.0175            1.25m\n",
      "        52           0.0171            1.23m\n",
      "        53           0.0168            1.21m\n",
      "        54           0.0164            1.19m\n",
      "        55           0.0162            1.16m\n",
      "        56           0.0157            1.14m\n",
      "        57           0.0154            1.11m\n",
      "        58           0.0151            1.09m\n",
      "        59           0.0148            1.06m\n",
      "        60           0.0145            1.04m\n",
      "        61           0.0143            1.02m\n",
      "        62           0.0140           59.43s\n",
      "        63           0.0136           58.00s\n",
      "        64           0.0132           56.61s\n",
      "        65           0.0131           55.08s\n",
      "        66           0.0128           53.61s\n",
      "        67           0.0126           52.18s\n",
      "        68           0.0123           50.79s\n",
      "        69           0.0122           49.24s\n",
      "        70           0.0121           47.69s\n",
      "        71           0.0118           46.21s\n",
      "        72           0.0117           44.68s\n",
      "        73           0.0114           43.12s\n",
      "        74           0.0112           41.58s\n",
      "        75           0.0111           39.97s\n",
      "        76           0.0109           38.49s\n",
      "        77           0.0109           36.96s\n",
      "        78           0.0106           35.45s\n",
      "        79           0.0105           33.84s\n",
      "        80           0.0104           32.29s\n",
      "        81           0.0102           30.68s\n",
      "        82           0.0101           29.09s\n",
      "        83           0.0099           27.49s\n",
      "        84           0.0098           25.87s\n",
      "        85           0.0096           24.26s\n",
      "        86           0.0095           22.66s\n",
      "        87           0.0093           21.09s\n",
      "        88           0.0092           19.47s\n",
      "        89           0.0091           17.88s\n",
      "        90           0.0089           16.26s\n",
      "        91           0.0088           14.64s\n",
      "        92           0.0087           13.02s\n",
      "        93           0.0085           11.41s\n",
      "        94           0.0084            9.78s\n",
      "        95           0.0082            8.15s\n",
      "        96           0.0081            6.53s\n",
      "        97           0.0080            4.90s\n",
      "        98           0.0079            3.26s\n",
      "        99           0.0078            1.63s\n",
      "       100           0.0077            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=5,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=2, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'loss': ['deviance', 'exponential'], 'max_depth': [5, 10, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='average_precision', verbose=10)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_1_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'exponential', 'max_depth': 5}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_1_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([136.4306828 ,  79.72978301,   7.86400566, 141.36643181,\n",
       "        341.85882778, 418.2566916 ]),\n",
       " 'std_fit_time': array([ 5.98598527, 35.9459582 ,  0.37235557,  1.76928766,  8.27855583,\n",
       "        36.01976936]),\n",
       " 'mean_score_time': array([0.07197108, 0.05387154, 0.02344255, 0.08625913, 0.13936648,\n",
       "        0.17837415]),\n",
       " 'std_score_time': array([0.00784596, 0.01050749, 0.00331524, 0.00513458, 0.00842296,\n",
       "        0.00658454]),\n",
       " 'param_loss': masked_array(data=['deviance', 'deviance', 'deviance', 'exponential',\n",
       "                    'exponential', 'exponential'],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[5, 10, 20, 5, 10, 20],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'loss': 'deviance', 'max_depth': 5},\n",
       "  {'loss': 'deviance', 'max_depth': 10},\n",
       "  {'loss': 'deviance', 'max_depth': 20},\n",
       "  {'loss': 'exponential', 'max_depth': 5},\n",
       "  {'loss': 'exponential', 'max_depth': 10},\n",
       "  {'loss': 'exponential', 'max_depth': 20}],\n",
       " 'split0_test_score': array([0.61251455, 0.63356083, 0.59619058, 0.80180806, 0.82606611,\n",
       "        0.70868477]),\n",
       " 'split1_test_score': array([0.6533123 , 0.62337025, 0.58266496, 0.8010897 , 0.76029877,\n",
       "        0.730782  ]),\n",
       " 'split2_test_score': array([0.35639089, 0.68554138, 0.51642844, 0.8492644 , 0.82903558,\n",
       "        0.80954555]),\n",
       " 'split3_test_score': array([0.65044483, 0.5013126 , 0.62233878, 0.80400737, 0.76465782,\n",
       "        0.737349  ]),\n",
       " 'split4_test_score': array([0.52247596, 0.55473042, 0.67754543, 0.78333547, 0.7637609 ,\n",
       "        0.72665873]),\n",
       " 'mean_test_score': array([0.55902789, 0.59970332, 0.59903325, 0.80790112, 0.78876396,\n",
       "        0.74260409]),\n",
       " 'std_test_score': array([0.11180833, 0.06446391, 0.05254861, 0.02196848, 0.03171684,\n",
       "        0.03479464]),\n",
       " 'rank_test_score': array([6, 4, 5, 1, 2, 3], dtype=int32),\n",
       " 'split0_train_score': array([0.91361562, 1.        , 1.        , 0.94056236, 1.        ,\n",
       "        1.        ]),\n",
       " 'split1_train_score': array([0.7841492 , 1.        , 1.        , 0.95535638, 1.        ,\n",
       "        1.        ]),\n",
       " 'split2_train_score': array([0.34241482, 1.        , 1.        , 0.9501303 , 1.        ,\n",
       "        1.        ]),\n",
       " 'split3_train_score': array([0.96353769, 1.        , 1.        , 0.94397996, 1.        ,\n",
       "        1.        ]),\n",
       " 'split4_train_score': array([0.69099638, 1.        , 1.        , 0.96040027, 1.        ,\n",
       "        1.        ]),\n",
       " 'mean_train_score': array([0.73894274, 1.        , 1.        , 0.95008585, 1.        ,\n",
       "        1.        ]),\n",
       " 'std_train_score': array([2.20240948e-01, 9.93013661e-17, 4.96506831e-17, 7.24080730e-03,\n",
       "        0.00000000e+00, 7.02166694e-17])}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_1_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      0    1\n",
      "Class            \n",
      "0      85290    5\n",
      "1         28  120\n",
      "True positives = 120\n",
      "True negatives = 85290\n",
      "False positives = 5\n",
      "False negatives = 28\n",
      "Sensitivity = 0.8108108108108109\n",
      "Specificity = 0.9999413799167595\n"
     ]
    }
   ],
   "source": [
    "## Retrain with best parameters and test on test set\n",
    "\n",
    "gbc_2 = GradientBoostingClassifier(loss='exponential',\n",
    "                                   random_state=392,\n",
    "                                   max_depth=5)\n",
    "\n",
    "gbc_2.fit(x_train, y_train)\n",
    "pred_y_gbc_2 = gbc_2.predict(x_test)\n",
    "table_gbc_2_test = pd.crosstab(y_test, pred_y_gbc_2)\n",
    "print_results(table_gbc_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models['gbc_2'] = table_gbc_2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare model performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>true_negatives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>false_negatives</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logit_3</td>\n",
       "      <td>136</td>\n",
       "      <td>83695</td>\n",
       "      <td>1600</td>\n",
       "      <td>12</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.981242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ridge_2</td>\n",
       "      <td>93</td>\n",
       "      <td>85286</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>0.628378</td>\n",
       "      <td>0.999894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svm_4</td>\n",
       "      <td>114</td>\n",
       "      <td>85287</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.999906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn_2</td>\n",
       "      <td>99</td>\n",
       "      <td>85291</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>0.999953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfc_2</td>\n",
       "      <td>118</td>\n",
       "      <td>85289</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.999930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gbc_2</td>\n",
       "      <td>120</td>\n",
       "      <td>85290</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.999941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    models  true_positives  true_negatives  false_positives  false_negatives  \\\n",
       "0  logit_3             136           83695             1600               12   \n",
       "1  ridge_2              93           85286                9               55   \n",
       "2    svm_4             114           85287                8               34   \n",
       "3    knn_2              99           85291                4               49   \n",
       "4    rfc_2             118           85289                6               30   \n",
       "5    gbc_2             120           85290                5               28   \n",
       "\n",
       "   sensitivity  specificity  \n",
       "0     0.918919     0.981242  \n",
       "1     0.628378     0.999894  \n",
       "2     0.770270     0.999906  \n",
       "3     0.668919     0.999953  \n",
       "4     0.797297     0.999930  \n",
       "5     0.810811     0.999941  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_results(final_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient Boosting model finds the most true positives\n",
    "## for the lowest level of false positives\n",
    "\n",
    "## If want to get most true positive can use Logistic Regression\n",
    "## but get very large number of false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
